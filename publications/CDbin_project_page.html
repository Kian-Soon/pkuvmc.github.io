<style type="text/css">
    *.elegant {
        margin-left: 20px;
        margin-right: 120px;
        letter-spacing: 0.1px;
        word-spacing: 0.1px;
        line-height: 1.2em;
        text-indent: 0px;
        text-align: justify;
    }
</style> 
<p class="elegant">In this project page, we mainly introduce CDbin. </p>

<br />
<br />

<p class="elegant"><font color="blue" size=7><strong>Description to CDbin</strong></font></p>

<font color="red" size=3><strong>Abstract</strong></font> </font>
<p class="elegant">

V1 As an important computer vision task, image matching requires efficient and discriminative local descriptors. Most of existing descriptors like SIFT and ORB are hand-crafted. It is necessary to study more optimized descriptors through end-to-end learning. This paper proposes compact binary descriptors learned with a lightweight Convolutional Neural Network (CNN), which is efficient for training and testing. Specifically, we propose a CNN with no larger than five layers for descriptor learning. The resulting descriptors, i.e., Compact Discriminative binary descriptors (CDbin) are optimized with four complementary loss functions, i.e.,<br /><br />
1) triplet loss to ensure the discriminative power,<br /> 
2) quantization loss to decrease the quantization error, <br />
3) correlation loss to ensure the feature compactness,<br />
4) even-distribution loss to enrich the embedded information. <br />
Extensive experiments on two image patch datasets and three image retrieval datasets show that CDbin exhibits competitive performance compared with existing descriptors. For example, 64-bit CDbin substantially outperforms 256-bit ORB and 1024-bit SIFT on Hpatches dataset. Although generated by a shallow CNN, CDbin also outperforms several recent deep descriptors.

   
   <img src="./CSVTyjmFig1.png" width="700" class="center"><br /><br /><br />
</p>

<font color="red" size=3><strong>Results</strong></font> </font>
<p class="elegant">
Comparison of fpr95 with other descriptors on Brown dataset. In each column, dataset name with underline denotes the training set, the other one denotes the testing set. And test of Liberty(LIB), Notredame(ND), Yosemite(YOS) denotes supervised methods, all the combinations of the trian are shown. â€  denotes using deeper CNNs than ours. SP denotes supervised methods, USP denotes unsupervised methods and HC denotes hand-crafted methods.
<img src="./CSVTyjmTab6.png" width="800" class="center"><br /><br /><br />

</p>

<font color="red" size=3><strong>Results Examples</strong></font> </font>
<p class="elegant">
Sample image matching results on HPatches dataset. CDbin(5-256) and SIFT use MSER as keypoint detector. ORB use Harris detector.
<img src="./CSVTyjmFig8.png" width="800" class="center"><br /><br /><br />
</p>

<font color="red" size=3><strong>Codes and models</strong></font> </font>
<p class="elegant">

</p>

<font color="red" size=3><strong>Citation</strong></font> </font>
<p class="elegant">

</p>
