<style type="text/css">
    *.elegant {
        margin-left: 20px;
        margin-right: 120px;
        letter-spacing: 0.1px;
        word-spacing: 0.1px;
        line-height: 1.2em;
        text-indent: 0px;
        text-align: justify;
    }
</style> 
<p class="elegant">In this project page, we mainly introduce the MSMT17 dataset. </p>

<br />
<br />

<p class="elegant"><font color="blue" size=7><strong>Description to MSMT17</strong></font></p>

<p class="elegant">
<img src="./CVPR_MSMT17_Stas.jpg" width="1100"><br /><br /><br />
To collect a large-scale person re-identification dataset-MSMT17, we utilize an 15-camera network deployed in campus. This camera network contains 12 outdoor cameras and 3 indoor cameras. We select 4 days with different weather conditions in a month for video collection. For each day, 3 hours of videos taken in the morning, noon, and afternoon, respectively, are selected for pedestrian detection and annotation. Our final raw video set contains 180 hours of videos, 12 outdoor cameras, 3 indoor cameras, and 12 time slots. Faster RCNN is utilized for pedestrian bounding box detection. Three labelers go through the detected bounding boxes and annotate ID label for 2 months. Finally, 126,441 bounding boxes of 4,101 identities are annotated. Some statistics on  MSMT17 are shown in above. Compared with existing datasets, we summarize the new features in MSMT17 into the following aspects:<br /><br />
(1) Larger number of identities, bounding boxes, and cameras.<br />
(2) Complex scenes and backgrounds.<br />
(3) Multiple time slots result in severe lighting changes.<br />
(4) More reliable bounding box detector.<br />

</p>
<p class="elegant">
<table CellSpacing=1 WIDTH=80% border=1 cellpadding="0" >
    <tr>
    <td>Dataset</td> <td>MSMT17</td> <td>Duke [1] </td> <td>Market [2] </td> <td>CUHK03 [3] </td> <td>CUHK01 [4] </td> <td>VIPeR [5] </td> <td>PRID [6] </td> <td>CAVIAR [7] </td>
    </tr>
    <tr>
    <td>BBoxes</td> <td>126,441</td> <td>36,411</td> <td>32,668</td> <td>28,192</td> <td>3,884</td> <td>1,264</td> <td>1,134</td> <td>610</td>
    </tr>
    <tr>
    <td>Identities</td> <td>4,101</td> <td>1,812</td> <td>1,501</td> <td>1,467</td> <td>971</td> <td>632</td> <td>934</td> <td>72</td>
    </tr>
    <tr>
    <td>Cameras</td> <td>15</td> <td>8</td> <td>6</td> <td>2</td> <td>10</td> <td>2</td> <td>2</td> <td>2</td>
    </tr>
    <tr>
    <td>Detector</td> <td>Faster RCNN</td> <td>hand</td> <td>DPM</td> <td>DPM,hand</td> <td>hand</td> <td>hand</td> <td>hand</td> <td>hand</td>
    </tr>
    <tr>
    <td>Scene</td> <td>outdoor,indoor</td> <td>outdoor</td> <td>outdoor</td> <td>indoor</td> <td>indoor</td> <td>outdoor</td> <td>outdoor</td> <td>indoor</td>
    </tr>
</table>
</p>
<br />
<p class="elegant">

<p class="elegant">
If  you use this dataset in your research, please kindly cite our work as,<br />
<textarea rows="7" cols="115" readonly="true">
@inproceedings{wei2018cvpr,
  title={Person Trasfer GAN to Bridge Domain Gap for Person Re-Identification},
  author={Wei, Longhui and Zhang, Shiliang and Gao, Wen and Tian, Qi},
  booktitle={Computer Vision and Pattern Recognition, IEEE International Conference on},
  year={2018}
}
</textarea>
</p>



<font color="red" size=3><strong>New!</strong></font> </font></a><br/><br/>

    The summary <a href="./state_of_the_art.html"><font color="blue">state of the art methods</font></a> on MSMT17 is released.</br></br>
    The <a href="https://docs.google.com/forms/d/e/1FAIpQLScIGhLvB2GzIXjX1oFW0tNUWxkbK2l0fYG5Q9vX93ls2BVsQw/viewform?usp=sf_link"><font color="blue">dataset</font></a> on MSMT17 will be released soon.
</p>

<font color="red" size=3><strong>Reference</strong></font> </font>
<p class="elegant">
[1] Z. Zheng et al. Unlabeled samples generated by gan improve the person re-identification baseline in vitro. In ICCV, 2017.<br/>
[2] L. Zheng et al. Scalable person re-identification: A benchmark. In ICCV, 2015.<br/>
[3] W. Li et al. Deepreid: Deep filter 918 pairing neural network for person re-identification. In CVPR, 2014.<br/>
[4] W. Li et al. Human reidentification with transferred metric learning. In ACCV, 2012.<br/>
[5] D. Gray et al. Viewpoint invariant pedestrian recogni- tion with an ensemble of localized features. In ECCV, 2008.<br/>
[6] M. Hirzer et al. Person re-identification by descriptive and discriminative classifica- tion. In SCIA, 2011.<br/>
[7] D. S. Cheng et al. Custom pictorial structures for re-identification. In BMVC, 2011.<br/>
</p>

